{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "african-verse",
   "metadata": {},
   "source": [
    "<img width=\"150\" alt=\"Logo_ER10\" src=\"https://user-images.githubusercontent.com/3244249/151994514-b584b984-a148-4ade-80ee-0f88b0aefa45.png\">\n",
    "\n",
    "### Interpreting the sentence classification model with LIME\n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) is an explainable-AI method that aims to create an interpretable model that locally represents the classifier. For more details see the [LIME paper](https://arxiv.org/abs/1602.04938).\n",
    "\n",
    "Note that this notebook was adapted from the [LIME/text tutorial for DIANNA](https://github.com/dianna-ai/dianna/blob/main/tutorials/lime_text.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d17b0",
   "metadata": {},
   "source": [
    "#### Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471630ff",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-15T09:54:37.185830Z",
     "end_time": "2024-05-15T09:54:37.218893Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from classify_text_with_inlegal_bert_xgboost import classify_texts\n",
    "\n",
    "running_in_colab = 'google.colab' in str(get_ipython())\n",
    "if running_in_colab:\n",
    "  # install dianna\n",
    "  !python3 -m pip install dianna[notebooks]\n",
    "  \n",
    "  # download data used in this demo\n",
    "  import os \n",
    "  base_url = 'https://raw.githubusercontent.com/dianna-ai/dianna/main/tutorials/'\n",
    "  paths_to_download = ['data/movie_reviews_word_vectors.txt', 'models/movie_review_model.onnx']\n",
    "  for path in paths_to_download:\n",
    "      !wget {base_url + path} -P {os.path.dirname(path)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf6f82-c1c7-4814-ae0f-5a1c0b8578f6",
   "metadata": {},
   "source": [
    "#### 1. Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b556d8-5337-44dc-8efe-14d1dff6f011",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-15T09:54:30.819163Z",
     "end_time": "2024-05-15T09:54:30.832141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ChristiaanMeijer\\anaconda3\\envs\\eulaw310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from torchtext.vocab import Vectors\n",
    "from scipy.special import expit as sigmoid\n",
    "from pathlib import Path\n",
    "\n",
    "import dianna\n",
    "from dianna import visualization\n",
    "from dianna import utils\n",
    "from dianna.utils.tokenizers import SpacyTokenizer\n",
    "from train_inlegalbert_xgboost import class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c616916c-78ef-48d0-a744-b25b37b62a3f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-15T09:57:37.804455Z",
     "end_time": "2024-05-15T09:57:37.829512Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = Path('inlegal_bert_xgboost_classifier.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Some test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "constitutive_statement_0 = \"The purchase, import or transport from Syria of crude oil and petroleum products shall be prohibited.\"\n",
    "constitutive_statement_1 = \"This Decision shall enter into force on the twentieth day following that of its publication in the Official Journal of the European Union.\"\n",
    "regulatory_statement_0 = \"Where observations are submitted, or where substantial new evidence is presented, the Council shall review its decision and inform the person or entity concerned accordingly.\"\n",
    "regulatory_statement_1 = \"The relevant Member State shall inform the other Member States of any authorisation granted under this Article.\"\n",
    "regulatory_statement_2 = \"Member States shall cooperate, in accordance with their national legislation, with inspections and disposals undertaken pursuant to paragraphs 1 and 2.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-15T09:58:44.103483Z",
     "end_time": "2024-05-15T09:58:44.126479Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "bad4f5b1-6097-4ef3-98c4-78432ad640b0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T10:28:34.456937Z",
     "end_time": "2024-03-21T10:28:34.466985Z"
    }
   },
   "source": [
    "Loading the model\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "555842c5-3f82-4f63-93bb-696645d4b447",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-15T09:58:44.919366Z",
     "end_time": "2024-05-15T09:58:44.934942Z"
    }
   },
   "outputs": [],
   "source": [
    "class StatementClassifier:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = SpacyTokenizer(name='en_core_web_sm')\n",
    "\n",
    "    def __call__(self, sentences):\n",
    "        # ensure the input has a batch axis\n",
    "        if isinstance(sentences, str):\n",
    "            sentences = [sentences]\n",
    "\n",
    "        probs = classify_texts(sentences, model_path, return_proba=True)\n",
    "\n",
    "        return np.transpose([(probs[:, 0]), (1 - probs[:, 0])])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "443e8a99-6fa3-4a73-9311-2fbe0251c2b1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-15T09:58:45.616365Z",
     "end_time": "2024-05-15T09:58:47.579566Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model runner. max_filter_size is a property of the model\n",
    "model_runner = StatementClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at law-ai/InLegalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating features: 100%|██████████| 5/5 [00:00<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from inlegal_bert_xgboost_classifier.json.\n"
     ]
    },
    {
     "data": {
      "text/plain": "['constitutive', 'constitutive', 'regulatory', 'regulatory', 'regulatory']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model_runner([constitutive_statement_0,constitutive_statement_1, regulatory_statement_0, regulatory_statement_1,regulatory_statement_2])\n",
    "[class_names[m] for m in np.argmax(prediction, axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-15T09:58:48.578586Z",
     "end_time": "2024-05-15T09:58:50.226361Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set parameters for DIANNA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_of_interest is regulatory\n"
     ]
    }
   ],
   "source": [
    "label_of_interest = 1\n",
    "print('label_of_interest is', class_names[label_of_interest])\n",
    "statement = regulatory_statement_0\n",
    "num_samples = 1000\n",
    "num_features=100  # top n number of words to include in the attribution map\n",
    "\n",
    "def run_dianna(input_text):\n",
    "    return dianna.explain_text(model_runner, input_text, model_runner.tokenizer,\n",
    "                               'LIME', labels=[label_of_interest], num_samples=num_samples, num_features=num_features, )[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-21T12:10:53.347050Z",
     "end_time": "2024-03-21T12:10:53.354051Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Are the results stable with current parameters?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at law-ai/InLegalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating features: 100%|██████████| 1000/1000 [01:55<00:00,  8.66it/s]\n",
      "Some weights of the model checkpoint at law-ai/InLegalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating features: 100%|██████████| 1000/1000 [01:59<00:00,  8.40it/s]\n",
      "Some weights of the model checkpoint at law-ai/InLegalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating features: 100%|██████████| 1000/1000 [02:03<00:00,  8.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Where  observations       are  submitted         ,        or  \\\ncount  3.000000      3.000000  3.000000   3.000000  3.000000  3.000000   \nmean  -0.005973      0.033819  0.044202   0.050789  0.074258  0.064762   \nstd    0.016238      0.006634  0.014064   0.016550  0.014820  0.028109   \nmin   -0.023122      0.026857  0.028155   0.032984  0.057950  0.046526   \n25%   -0.013544      0.030694  0.039109   0.043332  0.067935  0.048576   \n50%   -0.003966      0.034531  0.050063   0.053681  0.077920  0.050626   \n75%    0.002601      0.037300  0.052225   0.059691  0.082412  0.073880   \nmax    0.009168      0.040068  0.054388   0.065702  0.086903  0.097133   \n\n          where  substantial       new  evidence  ...  decision       and  \\\ncount  3.000000     3.000000  3.000000  3.000000  ...  3.000000  3.000000   \nmean   0.023754     0.034969  0.069220  0.082735  ...  0.038275  0.096304   \nstd    0.011242     0.024919  0.010647  0.004493  ...  0.021006  0.024024   \nmin    0.016915     0.007785  0.057084  0.080027  ...  0.015405  0.068844   \n25%    0.017266     0.024089  0.065336  0.080142  ...  0.029058  0.087733   \n50%    0.017618     0.040393  0.073589  0.080257  ...  0.042711  0.106622   \n75%    0.027174     0.048561  0.075288  0.084089  ...  0.049710  0.110034   \nmax    0.036729     0.056730  0.076988  0.087921  ...  0.056709  0.113446   \n\n         inform       the    person        or    entity  concerned  \\\ncount  3.000000  3.000000  3.000000  3.000000  3.000000   3.000000   \nmean   0.095057  0.063708  0.012272  0.058115  0.052506   0.082051   \nstd    0.020876  0.029332  0.035683  0.013160  0.014422   0.013582   \nmin    0.071017  0.030647 -0.021165  0.044011  0.042107   0.066830   \n25%    0.088275  0.052257 -0.006513  0.052140  0.044274   0.076609   \n50%    0.105532  0.073868  0.008138  0.060269  0.046440   0.086389   \n75%    0.107076  0.080239  0.028990  0.065167  0.057705   0.089662   \nmax    0.108620  0.086610  0.049842  0.070064  0.068970   0.092935   \n\n       accordingly         .  \ncount     3.000000  3.000000  \nmean      0.071340  0.049662  \nstd       0.033703  0.010203  \nmin       0.033687  0.038507  \n25%       0.057666  0.045231  \n50%       0.081645  0.051956  \n75%       0.090166  0.055239  \nmax       0.098686  0.058523  \n\n[8 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Where</th>\n      <th>observations</th>\n      <th>are</th>\n      <th>submitted</th>\n      <th>,</th>\n      <th>or</th>\n      <th>where</th>\n      <th>substantial</th>\n      <th>new</th>\n      <th>evidence</th>\n      <th>...</th>\n      <th>decision</th>\n      <th>and</th>\n      <th>inform</th>\n      <th>the</th>\n      <th>person</th>\n      <th>or</th>\n      <th>entity</th>\n      <th>concerned</th>\n      <th>accordingly</th>\n      <th>.</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>...</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-0.005973</td>\n      <td>0.033819</td>\n      <td>0.044202</td>\n      <td>0.050789</td>\n      <td>0.074258</td>\n      <td>0.064762</td>\n      <td>0.023754</td>\n      <td>0.034969</td>\n      <td>0.069220</td>\n      <td>0.082735</td>\n      <td>...</td>\n      <td>0.038275</td>\n      <td>0.096304</td>\n      <td>0.095057</td>\n      <td>0.063708</td>\n      <td>0.012272</td>\n      <td>0.058115</td>\n      <td>0.052506</td>\n      <td>0.082051</td>\n      <td>0.071340</td>\n      <td>0.049662</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.016238</td>\n      <td>0.006634</td>\n      <td>0.014064</td>\n      <td>0.016550</td>\n      <td>0.014820</td>\n      <td>0.028109</td>\n      <td>0.011242</td>\n      <td>0.024919</td>\n      <td>0.010647</td>\n      <td>0.004493</td>\n      <td>...</td>\n      <td>0.021006</td>\n      <td>0.024024</td>\n      <td>0.020876</td>\n      <td>0.029332</td>\n      <td>0.035683</td>\n      <td>0.013160</td>\n      <td>0.014422</td>\n      <td>0.013582</td>\n      <td>0.033703</td>\n      <td>0.010203</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.023122</td>\n      <td>0.026857</td>\n      <td>0.028155</td>\n      <td>0.032984</td>\n      <td>0.057950</td>\n      <td>0.046526</td>\n      <td>0.016915</td>\n      <td>0.007785</td>\n      <td>0.057084</td>\n      <td>0.080027</td>\n      <td>...</td>\n      <td>0.015405</td>\n      <td>0.068844</td>\n      <td>0.071017</td>\n      <td>0.030647</td>\n      <td>-0.021165</td>\n      <td>0.044011</td>\n      <td>0.042107</td>\n      <td>0.066830</td>\n      <td>0.033687</td>\n      <td>0.038507</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.013544</td>\n      <td>0.030694</td>\n      <td>0.039109</td>\n      <td>0.043332</td>\n      <td>0.067935</td>\n      <td>0.048576</td>\n      <td>0.017266</td>\n      <td>0.024089</td>\n      <td>0.065336</td>\n      <td>0.080142</td>\n      <td>...</td>\n      <td>0.029058</td>\n      <td>0.087733</td>\n      <td>0.088275</td>\n      <td>0.052257</td>\n      <td>-0.006513</td>\n      <td>0.052140</td>\n      <td>0.044274</td>\n      <td>0.076609</td>\n      <td>0.057666</td>\n      <td>0.045231</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.003966</td>\n      <td>0.034531</td>\n      <td>0.050063</td>\n      <td>0.053681</td>\n      <td>0.077920</td>\n      <td>0.050626</td>\n      <td>0.017618</td>\n      <td>0.040393</td>\n      <td>0.073589</td>\n      <td>0.080257</td>\n      <td>...</td>\n      <td>0.042711</td>\n      <td>0.106622</td>\n      <td>0.105532</td>\n      <td>0.073868</td>\n      <td>0.008138</td>\n      <td>0.060269</td>\n      <td>0.046440</td>\n      <td>0.086389</td>\n      <td>0.081645</td>\n      <td>0.051956</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.002601</td>\n      <td>0.037300</td>\n      <td>0.052225</td>\n      <td>0.059691</td>\n      <td>0.082412</td>\n      <td>0.073880</td>\n      <td>0.027174</td>\n      <td>0.048561</td>\n      <td>0.075288</td>\n      <td>0.084089</td>\n      <td>...</td>\n      <td>0.049710</td>\n      <td>0.110034</td>\n      <td>0.107076</td>\n      <td>0.080239</td>\n      <td>0.028990</td>\n      <td>0.065167</td>\n      <td>0.057705</td>\n      <td>0.089662</td>\n      <td>0.090166</td>\n      <td>0.055239</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.009168</td>\n      <td>0.040068</td>\n      <td>0.054388</td>\n      <td>0.065702</td>\n      <td>0.086903</td>\n      <td>0.097133</td>\n      <td>0.036729</td>\n      <td>0.056730</td>\n      <td>0.076988</td>\n      <td>0.087921</td>\n      <td>...</td>\n      <td>0.056709</td>\n      <td>0.113446</td>\n      <td>0.108620</td>\n      <td>0.086610</td>\n      <td>0.049842</td>\n      <td>0.070064</td>\n      <td>0.068970</td>\n      <td>0.092935</td>\n      <td>0.098686</td>\n      <td>0.058523</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation_relevances = [run_dianna(statement) for i in range(3)]\n",
    "sorted_relevances = [sorted(r, key=lambda t : t[1]) for r in explanation_relevances]\n",
    "\n",
    "pd.DataFrame([[r[2] for r in sr] for sr in sorted_relevances], columns=[r[0] for r in sorted_relevances[0]]).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-21T11:57:43.921805Z",
     "end_time": "2024-03-21T11:57:43.971896Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems quite stable with 1000 samples in LIME. We can now run DIANNA knowing results will contain mostly signal and not just noise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at law-ai/InLegalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating features: 100%|██████████| 1000/1000 [01:57<00:00,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributions for class regulatory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "               0   1         2\n0         inform  20  0.117588\n1              ,  12  0.099412\n2            are   2  0.090272\n3    accordingly  26  0.089739\n4              .  27  0.089180\n5         review  16  0.087251\n6       evidence   9  0.082871\n7          shall  15  0.081039\n8            and  19  0.080405\n9            its  17  0.078664\n10           new   8  0.071281\n11      decision  18  0.068433\n12           the  21  0.065975\n13     concerned  25  0.060685\n14            or   5  0.059969\n15             ,   4  0.049138\n16         where   6  0.045673\n17  observations   1  0.044398\n18           the  13  0.044379\n19            is  10  0.039317\n20   substantial   7  0.037653\n21        entity  24  0.034751\n22        person  22  0.026545\n23            or  23  0.023060\n24       Council  14  0.016188\n25     submitted   3  0.014200\n26         Where   0 -0.004694\n27     presented  11  0.003050",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>inform</td>\n      <td>20</td>\n      <td>0.117588</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>,</td>\n      <td>12</td>\n      <td>0.099412</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>are</td>\n      <td>2</td>\n      <td>0.090272</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>accordingly</td>\n      <td>26</td>\n      <td>0.089739</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>.</td>\n      <td>27</td>\n      <td>0.089180</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>review</td>\n      <td>16</td>\n      <td>0.087251</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>evidence</td>\n      <td>9</td>\n      <td>0.082871</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>shall</td>\n      <td>15</td>\n      <td>0.081039</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>and</td>\n      <td>19</td>\n      <td>0.080405</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>its</td>\n      <td>17</td>\n      <td>0.078664</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>new</td>\n      <td>8</td>\n      <td>0.071281</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>decision</td>\n      <td>18</td>\n      <td>0.068433</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>the</td>\n      <td>21</td>\n      <td>0.065975</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>concerned</td>\n      <td>25</td>\n      <td>0.060685</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>or</td>\n      <td>5</td>\n      <td>0.059969</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>,</td>\n      <td>4</td>\n      <td>0.049138</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>where</td>\n      <td>6</td>\n      <td>0.045673</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>observations</td>\n      <td>1</td>\n      <td>0.044398</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>the</td>\n      <td>13</td>\n      <td>0.044379</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>is</td>\n      <td>10</td>\n      <td>0.039317</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>substantial</td>\n      <td>7</td>\n      <td>0.037653</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>entity</td>\n      <td>24</td>\n      <td>0.034751</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>person</td>\n      <td>22</td>\n      <td>0.026545</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>or</td>\n      <td>23</td>\n      <td>0.023060</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Council</td>\n      <td>14</td>\n      <td>0.016188</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>submitted</td>\n      <td>3</td>\n      <td>0.014200</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Where</td>\n      <td>0</td>\n      <td>-0.004694</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>presented</td>\n      <td>11</td>\n      <td>0.003050</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation_relevance = run_dianna(statement)\n",
    "print('attributions for class', class_names[label_of_interest])\n",
    "pd.DataFrame(explanation_relevance)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-21T12:04:15.320612Z",
     "end_time": "2024-03-21T12:06:11.072481Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "7e177746-3654-4518-9c1c-b7047f922273",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T10:38:41.425881Z",
     "end_time": "2024-03-21T10:38:43.263330Z"
    }
   },
   "source": [
    "#### Visualize the result\n",
    "DIANNA includes a visualization package, capable of highlighting the relevance of each word in the text for a chosen class. The visualization is in HTML format.\n",
    "Words in favour of the selected class are highlighted in red, while words against the selected class - in blue."
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at law-ai/InLegalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating features: 100%|██████████| 4/4 [00:00<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "['constitutive', 'constitutive', 'regulatory', 'regulatory']"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0136005d-a22f-43a0-80da-4ec1f283f870",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T12:06:24.987550Z",
     "end_time": "2024-03-21T12:06:25.001015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<mark style=\"background-color: hsl(240, 100%, 99%, 0.8); line-height:1.75\">Where</mark> <mark style=\"background-color: hsl(0, 100%, 82%, 0.8); line-height:1.75\">observations</mark> <mark style=\"background-color: hsl(0, 100%, 62%, 0.8); line-height:1.75\">are</mark> <mark style=\"background-color: hsl(0, 100%, 94%, 0.8); line-height:1.75\">submitted</mark> <mark style=\"background-color: hsl(0, 100%, 80%, 0.8); line-height:1.75\">,</mark> <mark style=\"background-color: hsl(0, 100%, 91%, 0.8); line-height:1.75\">or</mark> <mark style=\"background-color: hsl(0, 100%, 81%, 0.8); line-height:1.75\">where</mark> <mark style=\"background-color: hsl(0, 100%, 84%, 0.8); line-height:1.75\">substantial</mark> <mark style=\"background-color: hsl(0, 100%, 70%, 0.8); line-height:1.75\">new</mark> <mark style=\"background-color: hsl(0, 100%, 65%, 0.8); line-height:1.75\">evidence</mark> <mark style=\"background-color: hsl(0, 100%, 84%, 0.8); line-height:1.75\">is</mark> <mark style=\"background-color: hsl(0, 100%, 99%, 0.8); line-height:1.75\">presented</mark> <mark style=\"background-color: hsl(0, 100%, 80%, 0.8); line-height:1.75\">,</mark> <mark style=\"background-color: hsl(0, 100%, 82%, 0.8); line-height:1.75\">the</mark> <mark style=\"background-color: hsl(0, 100%, 94%, 0.8); line-height:1.75\">Council</mark> <mark style=\"background-color: hsl(0, 100%, 66%, 0.8); line-height:1.75\">shall</mark> <mark style=\"background-color: hsl(0, 100%, 63%, 0.8); line-height:1.75\">review</mark> <mark style=\"background-color: hsl(0, 100%, 67%, 0.8); line-height:1.75\">its</mark> <mark style=\"background-color: hsl(0, 100%, 71%, 0.8); line-height:1.75\">decision</mark> <mark style=\"background-color: hsl(0, 100%, 66%, 0.8); line-height:1.75\">and</mark> <mark style=\"background-color: hsl(0, 100%, 50%, 0.8); line-height:1.75\">inform</mark> <mark style=\"background-color: hsl(0, 100%, 82%, 0.8); line-height:1.75\">the</mark> <mark style=\"background-color: hsl(0, 100%, 89%, 0.8); line-height:1.75\">person</mark> <mark style=\"background-color: hsl(0, 100%, 91%, 0.8); line-height:1.75\">or</mark> <mark style=\"background-color: hsl(0, 100%, 86%, 0.8); line-height:1.75\">entity</mark> <mark style=\"background-color: hsl(0, 100%, 75%, 0.8); line-height:1.75\">concerned</mark> <mark style=\"background-color: hsl(0, 100%, 62%, 0.8); line-height:1.75\">accordingly</mark> <mark style=\"background-color: hsl(0, 100%, 63%, 0.8); line-height:1.75\">.</mark>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization.highlight_text(explanation_relevance, model_runner.tokenizer.tokenize(statement))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
