{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "african-verse",
   "metadata": {},
   "source": [
    "<img width=\"150\" alt=\"Logo_ER10\" src=\"https://user-images.githubusercontent.com/3244249/151994514-b584b984-a148-4ade-80ee-0f88b0aefa45.png\">\n",
    "\n",
    "### Interpreting the sentence classification model with LIME\n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) is an explainable-AI method that aims to create an interpretable model that locally represents the classifier. For more details see the [LIME paper](https://arxiv.org/abs/1602.04938).\n",
    "\n",
    "Note that this notebook was adapted from the [LIME/text tutorial for DIANNA](https://github.com/dianna-ai/dianna/blob/main/tutorials/lime_text.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d17b0",
   "metadata": {},
   "source": [
    "#### Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471630ff",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T10:57:47.924542Z",
     "end_time": "2024-03-21T10:57:51.771689Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from classify_text_with_inlegal_bert_xgboost import classify_texts\n",
    "\n",
    "running_in_colab = 'google.colab' in str(get_ipython())\n",
    "if running_in_colab:\n",
    "  # install dianna\n",
    "  !python3 -m pip install dianna[notebooks]\n",
    "  \n",
    "  # download data used in this demo\n",
    "  import os \n",
    "  base_url = 'https://raw.githubusercontent.com/dianna-ai/dianna/main/tutorials/'\n",
    "  paths_to_download = ['data/movie_reviews_word_vectors.txt', 'models/movie_review_model.onnx']\n",
    "  for path in paths_to_download:\n",
    "      !wget {base_url + path} -P {os.path.dirname(path)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf6f82-c1c7-4814-ae0f-5a1c0b8578f6",
   "metadata": {},
   "source": [
    "#### 1. Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34b556d8-5337-44dc-8efe-14d1dff6f011",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T11:18:04.332429Z",
     "end_time": "2024-03-21T11:18:04.339355Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from torchtext.vocab import Vectors\n",
    "from scipy.special import expit as sigmoid\n",
    "from pathlib import Path\n",
    "\n",
    "import dianna\n",
    "from dianna import visualization\n",
    "from dianna import utils\n",
    "from dianna.utils.tokenizers import SpacyTokenizer\n",
    "from train_inlegalbert_xgboost import class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c616916c-78ef-48d0-a744-b25b37b62a3f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T10:57:59.607043Z",
     "end_time": "2024-03-21T10:57:59.621499Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = Path('..\\inlegal_xgboost_classifier_xgboost_classifier.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Some test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "constitutive_statement_0 = \"The purchase, import or transport from Syria of crude oil and petroleum products shall be prohibited.\"\n",
    "constitutive_statement_1 = \"This Decision shall enter into force on the twentieth day following that of its publication in the Official Journal of the European Union.\"\n",
    "regulatory_statement_0 = \"Where observations are submitted, or where substantial new evidence is presented, the Council shall review its decision and inform the person or entity concerned accordingly.\"\n",
    "regulatory_statement_1 = \"The relevant Member State shall inform the other Member States of any authorisation granted under this Article.\"\n",
    "regulatory_statement_2 = \"Member States shall cooperate, in accordance with their national legislation, with inspections and disposals undertaken pursuant to paragraphs 1 and 2.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "bad4f5b1-6097-4ef3-98c4-78432ad640b0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T10:28:34.456937Z",
     "end_time": "2024-03-21T10:28:34.466985Z"
    }
   },
   "source": [
    "Loading the model\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "555842c5-3f82-4f63-93bb-696645d4b447",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T11:15:32.380424Z",
     "end_time": "2024-03-21T11:15:32.397960Z"
    }
   },
   "outputs": [],
   "source": [
    "class StatementClassifier:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = SpacyTokenizer(name='en_core_web_sm')\n",
    "\n",
    "    def __call__(self, sentences):\n",
    "        # ensure the input has a batch axis\n",
    "        if isinstance(sentences, str):\n",
    "            sentences = [sentences]\n",
    "\n",
    "        probs = classify_texts(sentences, model_path, return_proba=True)\n",
    "\n",
    "        return np.transpose([(probs[:, 0]), (1 - probs[:, 0])])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "443e8a99-6fa3-4a73-9311-2fbe0251c2b1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T11:15:33.323756Z",
     "end_time": "2024-03-21T11:15:33.780511Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model runner. max_filter_size is a property of the model\n",
    "model_runner = StatementClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at law-ai/InLegalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating features: 100%|██████████| 5/5 [00:00<00:00, 17.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "['constitutive', 'constitutive', 'regulatory', 'regulatory', 'regulatory']"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model_runner([constitutive_statement_0,constitutive_statement_1, regulatory_statement_0, regulatory_statement_1,regulatory_statement_2])\n",
    "[class_names[m] for m in np.argmax(prediction, axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-21T11:15:33.811870Z",
     "end_time": "2024-03-21T11:15:35.319350Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Apply LIME with DIANNA\n",
    "The simplest way to run DIANNA on text data is with `dianna.explain_text`. The arguments are:\n",
    "* The function that runs the model (a path to a model in ONNX format is also accepted)\n",
    "* The text we want to explain\n",
    "* The name of the explainable-AI method we want to use, here LIME\n",
    "* The numerical index of the class we want an explanation for\n",
    "\n",
    "`dianna.explain_text` returns a list of tuples. Each tuple contains a word, its location in the input text, and its importance for the selected output class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c0bfd7d-df1d-4981-b714-496bc16b9347",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T11:18:14.039918Z",
     "end_time": "2024-03-21T11:18:26.923706Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at law-ai/InLegalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating features: 100%|██████████| 100/100 [00:11<00:00,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributions for class regulatory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "             0   1         2\n0          its  17  0.219725\n1     evidence   9  0.219297\n2  accordingly  26  0.196463\n3        shall  15  0.193062\n4            ,  12  0.175377\n5       entity  24 -0.145893\n6          the  13  0.143410\n7        where   6  0.140912\n8          are   2  0.131716\n9          new   8  0.125557",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>its</td>\n      <td>17</td>\n      <td>0.219725</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>evidence</td>\n      <td>9</td>\n      <td>0.219297</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>accordingly</td>\n      <td>26</td>\n      <td>0.196463</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>shall</td>\n      <td>15</td>\n      <td>0.193062</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>,</td>\n      <td>12</td>\n      <td>0.175377</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>entity</td>\n      <td>24</td>\n      <td>-0.145893</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>the</td>\n      <td>13</td>\n      <td>0.143410</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>where</td>\n      <td>6</td>\n      <td>0.140912</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>are</td>\n      <td>2</td>\n      <td>0.131716</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>new</td>\n      <td>8</td>\n      <td>0.125557</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're getting the explanation for the 'positive' class only,\n",
    "# but dianna supports explaining for multiple labels in one go.\n",
    "# It therefore always outputs a list of saliency maps. We want\n",
    "# the first and only saliency map from this list here.\n",
    "label = 1\n",
    "statement = regulatory_statement_0\n",
    "explanation_relevance = dianna.explain_text(model_runner, statement, model_runner.tokenizer,\n",
    "                                            'LIME', labels=[label], num_samples=100)[0]\n",
    "print('attributions for class', class_names[label])\n",
    "pd.DataFrame(explanation_relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e177746-3654-4518-9c1c-b7047f922273",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T10:38:41.425881Z",
     "end_time": "2024-03-21T10:38:43.263330Z"
    }
   },
   "source": [
    "#### Visualize the result\n",
    "DIANNA includes a visualization package, capable of highlighting the relevance of each word in the text for a chosen class. The visualization is in HTML format.\n",
    "Words in favour of the selected class are highlighted in red, while words against the selected class - in blue."
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at law-ai/InLegalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating features: 100%|██████████| 4/4 [00:00<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "['constitutive', 'constitutive', 'regulatory', 'regulatory']"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0136005d-a22f-43a0-80da-4ec1f283f870",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T11:18:39.684019Z",
     "end_time": "2024-03-21T11:18:39.703019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">Where</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">observations</mark> <mark style=\"background-color: hsl(0, 100%, 71%, 0.8); line-height:1.75\">are</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">submitted</mark> <mark style=\"background-color: hsl(0, 100%, 61%, 0.8); line-height:1.75\">,</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">or</mark> <mark style=\"background-color: hsl(0, 100%, 68%, 0.8); line-height:1.75\">where</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">substantial</mark> <mark style=\"background-color: hsl(0, 100%, 72%, 0.8); line-height:1.75\">new</mark> <mark style=\"background-color: hsl(0, 100%, 51%, 0.8); line-height:1.75\">evidence</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">is</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">presented</mark> <mark style=\"background-color: hsl(0, 100%, 61%, 0.8); line-height:1.75\">,</mark> <mark style=\"background-color: hsl(0, 100%, 68%, 0.8); line-height:1.75\">the</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">Council</mark> <mark style=\"background-color: hsl(0, 100%, 57%, 0.8); line-height:1.75\">shall</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">review</mark> <mark style=\"background-color: hsl(0, 100%, 50%, 0.8); line-height:1.75\">its</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">decision</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">and</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">inform</mark> <mark style=\"background-color: hsl(0, 100%, 68%, 0.8); line-height:1.75\">the</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">person</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">or</mark> <mark style=\"background-color: hsl(240, 100%, 67%, 0.8); line-height:1.75\">entity</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">concerned</mark> <mark style=\"background-color: hsl(0, 100%, 56%, 0.8); line-height:1.75\">accordingly</mark> <mark style=\"background-color: hsl(0, 0%, 75%, 0.8); line-height:1.75\">.</mark>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization.highlight_text(explanation_relevance, model_runner.tokenizer.tokenize(statement))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
